{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 04 — Simulate Returns, Compute VaR/CVaR, and Stress Test\n",
    "\n",
    "**Objective**\n",
    "- Map **simulated uniforms** (from the Gaussian copula) back to **returns** using inverse t-CDF.\n",
    "- Build an **equal-weight portfolio** and compute **VaR/CVaR** at 95% & 99%.\n",
    "- Compare **Copula-based**, **Historical**, and **Gaussian parametric** risk.\n",
    "- Run a **conditional stress test** (fix XLK = −5%) and analyze impact.\n",
    "- Save figures and result tables under `figures/` and `data/processed/`.\n"
   ],
   "id": "42ea484db7c499d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import joblib\n",
    "\n",
    "from quantcopula.data import get_prices\n",
    "from quantcopula.margins import fit_student_t_params, from_uniforms, frame_to_params\n",
    "from quantcopula.copula import sample_copula\n",
    "from quantcopula.risk import (\n",
    "    var_cvar,\n",
    "    portfolio_equal_weight,\n",
    "    gaussian_parametric_var_cvar,\n",
    ")\n",
    "from quantcopula.plotting import (\n",
    "    plot_hist,\n",
    "    plot_ecdf_with_lines,\n",
    ")\n",
    "\n",
    "# Paths & constants\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "ALPHA_LIST = [0.95, 0.99]\n",
    "N_SAMPLES  = 10_000  # for extra simulations if needed\n"
   ],
   "id": "f48f338db6085f7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load previously saved artifacts from notebooks 01–03\n",
    "prices = get_prices(\n",
    "    [\"XLK\", \"XLF\", \"XLI\", \"XLV\"],\n",
    "    \"2013-01-01\",\n",
    "    \"2023-12-31\",\n",
    "    cache_path=\"data/raw/prices.parquet\",\n",
    "    auto_adjust=False,\n",
    ").dropna(how=\"any\")\n",
    "log_returns = np.log(prices / prices.shift(1)).dropna(how=\"any\")\n",
    "\n",
    "# Fitted Student-t parameters\n",
    "params_df = pd.read_csv(\"data/processed/t_params.csv\")\n",
    "params = frame_to_params(params_df)\n",
    "\n",
    "# Empirical uniforms (from PIT)\n",
    "U_empirical = pd.read_parquet(\"data/processed/uniforms.parquet\")\n",
    "\n",
    "# Fitted Gaussian copula\n",
    "copula = joblib.load(\"data/processed/gaussian_copula.pkl\")\n",
    "\n",
    "# Simulated uniforms (from 03), or regenerate if desired\n",
    "U_sim = pd.read_parquet(\"data/processed/u_simulated.parquet\")\n",
    "U_sim = U_sim[U_empirical.columns]  # ensure consistent column order\n",
    "U_sim.head()\n"
   ],
   "id": "5c3e05792d14133"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Inverse PIT\n",
    "Convert uniforms back to returns using the fitted t parameters for each asset.\n"
   ],
   "id": "277972e79aff5052"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "simulated_returns = from_uniforms(U_sim, params)\n",
    "simulated_returns.to_parquet(\"data/processed/simulated_returns.parquet\")\n",
    "\"data/processed/simulated_returns.parquet\"\n"
   ],
   "id": "f416897da5bb7c0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Portfolio VaR/CVaR\n",
    "Compute risk on:\n",
    "- **Copula-based simulations** (non-parametric VaR/CVaR)\n",
    "- **Historical returns** (non-parametric VaR/CVaR)\n",
    "- **Gaussian parametric** (μ, σ fitted on historical)\n"
   ],
   "id": "604db64f60955206"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "port_sim  = portfolio_equal_weight(simulated_returns)\n",
    "port_hist = portfolio_equal_weight(log_returns)\n",
    "\n",
    "def risk_table(port_series, label):\n",
    "    rows = []\n",
    "    for a in ALPHA_LIST:\n",
    "        v, c = var_cvar(port_series.values, a)\n",
    "        rows.append({\"Model\": label, \"Alpha\": a, \"VaR\": v, \"CVaR\": c})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "tbl_cop = risk_table(port_sim,  \"Copula-Based\")\n",
    "tbl_hist= risk_table(port_hist, \"Historical\")\n",
    "\n",
    "# Gaussian parametric on historical\n",
    "rows_g = []\n",
    "for a in ALPHA_LIST:\n",
    "    v, c = gaussian_parametric_var_cvar(port_hist, a)\n",
    "    rows_g.append({\"Model\": \"Gaussian (Hist)\", \"Alpha\": a, \"VaR\": v, \"CVaR\": c})\n",
    "tbl_gauss = pd.DataFrame(rows_g)\n",
    "\n",
    "risk_comparison = pd.concat([tbl_cop, tbl_hist, tbl_gauss], ignore_index=True)\n",
    "risk_comparison.to_csv(\"data/processed/risk_comparison_long.csv\", index=False, float_format=\"%.6f\")\n",
    "risk_comparison.pivot(index=\"Model\", columns=\"Alpha\", values=[\"VaR\", \"CVaR\"]).round(4)\n"
   ],
   "id": "ef4d85077eadaef6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Histogram (simulated portfolio)\n",
    "plot_hist(port_sim, \"figures/portfolio_hist.png\", \"Simulated Portfolio Return (10k scenarios)\")\n",
    "\n",
    "# ECDF with VaR/CVaR markers (95% & 99%)\n",
    "sorted_ret = np.sort(port_sim.values)\n",
    "ecdf = np.arange(1, len(sorted_ret) + 1) / len(sorted_ret)\n",
    "\n",
    "v95, c95 = var_cvar(port_sim.values, 0.95)\n",
    "v99, c99 = var_cvar(port_sim.values, 0.99)\n",
    "plot_ecdf_with_lines(sorted_ret, ecdf, {\n",
    "    \"VaR 95%\": v95, \"CVaR 95%\": c95, \"VaR 99%\": v99, \"CVaR 99%\": c99\n",
    "}, out_path=\"figures/portfolio_ecdf.png\")\n"
   ],
   "id": "c923deda82a09417"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conditional Stress Test: Fix **XLK = −5%**\n",
    "1. Convert −5% to **U-space** via the fitted t-CDF for XLK.\n",
    "2. Sample uniforms from the copula and **override** `U[\"XLK\"]` with that fixed value.\n",
    "3. Inverse PIT back to returns, build portfolio, and recompute VaR/CVaR.\n"
   ],
   "id": "a3ff96899352d631"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "asset = \"XLK\"\n",
    "# Map −5% to U-space using t CDF and fitted params\n",
    "df, loc, scale = params[asset]\n",
    "u_fixed = stats.t.cdf(-0.05, df, loc=loc, scale=scale)\n",
    "\n",
    "# Generate new uniforms and fix XLK dimension\n",
    "U_cond = sample_copula(copula, N_SAMPLES, U_empirical.columns)\n",
    "U_cond[asset] = float(u_fixed)\n",
    "\n",
    "# Back to returns\n",
    "cond_returns = from_uniforms(U_cond, params)\n",
    "port_cond = portfolio_equal_weight(cond_returns)\n",
    "\n",
    "# Risk under stress\n",
    "v95_c, c95_c = var_cvar(port_cond.values, 0.95)\n",
    "v99_c, c99_c = var_cvar(port_cond.values, 0.99)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Metric\": [\"VaR 95%\", \"CVaR 95%\", \"VaR 99%\", \"CVaR 99%\"],\n",
    "    \"Baseline\": [v95, c95, v99, c99],\n",
    "    \"Conditional (XLK=-5%)\": [v95_c, c95_c, v99_c, c99_c],\n",
    "}).round(4)\n"
   ],
   "id": "c27324c79879153b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_hist(port_cond, \"figures/portfolio_hist_conditional.png\",\n",
    "          \"Portfolio Return (Conditioned on XLK = −5%)\")\n"
   ],
   "id": "df919aae17e30980"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Saved Artifacts\n",
    "- `data/processed/simulated_returns.parquet`\n",
    "- `data/processed/risk_comparison_long.csv`\n",
    "- `figures/portfolio_hist.png`\n",
    "- `figures/portfolio_ecdf.png`\n",
    "- `figures/portfolio_hist_conditional.png`\n",
    "\n",
    "## Takeaways\n",
    "- Copula-based simulation captures dependence beyond simple Gaussian parametrics.\n",
    "- VaR/CVaR (copula) typically shows heavier tails than Gaussian (depending on data).\n",
    "- Conditioning **XLK = −5%** deepens left-tail risk — useful for scenario analysis.\n"
   ],
   "id": "22ba5f3befd6c05a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
